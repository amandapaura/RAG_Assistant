# ğŸ—ï¸ Arquitetura - RAG Assistant

## ğŸ“Œ VisÃ£o Geral
O **RAG Assistant** Ã© um sistema de assistente conversacional baseado em **RAG (Retrieval-Augmented Generation)**, construÃ­do apenas com tecnologias **open source**.  
A aplicaÃ§Ã£o integra **busca vetorial**, **busca na web**, **consulta de previsÃ£o do tempo** e **LLMs open source**, oferecendo uma interface interativa via **Streamlit**.

---

## ğŸ”¹ Componentes Principais

- **Frontend**
  - Streamlit (interface de chat em tempo real)
  - ConfiguraÃ§Ãµes de parÃ¢metros (alguns ainda em default, ex: `confidence=0.3`)

- **OrquestraÃ§Ã£o**
  - LangGraph (implementaÃ§Ã£o atual com router simples)

- **Agentes**
  - **RAG Agent** â†’ Busca em documentos com Qdrant
  - **Web Agent** â†’ Busca de informaÃ§Ãµes na web
  - **Weather Agent** â†’ Consulta API de clima
  - **SQL Agent** â†’ (planejado/expandÃ­vel)

- **Modelos de Linguagem (LLMs)**
  - Hugging Face (modelos open source)
  - LLaMA Tiny (teste de geraÃ§Ã£o contextual baseada nos documentos recuperados)

- **Vector Database**
  - Qdrant (armazenamento de embeddings e similarity search)

- **Embeddings**
  - Sentence Transformers

---

## ğŸ”¹ Fluxo de Funcionamento

1. UsuÃ¡rio envia uma pergunta pela interface Streamlit  
   â†“  
2. **Router (LangGraph)** direciona para o agente adequado (RAG, Web, Weather, SQL)  
   â†“  
3. Agente selecionado executa a ferramenta:  
   - RAG â†’ consulta no Qdrant  
   - Web â†’ busca externa  
   - Weather â†’ chamada Ã  API de clima  
   â†“  
4. Resultados retornam para o **LLM Manager**  
   - (Se RAG) LLaMA Tiny gera resposta baseada no contexto recuperado  
   â†“  
5. Resposta Ã© formatada e exibida ao usuÃ¡rio na interface  

---

## ğŸ”¹ Infraestrutura

- **Docker-Compose** para orquestraÃ§Ã£o dos serviÃ§os
  - `app` â†’ aplicaÃ§Ã£o principal (Streamlit + agentes)
  - `qdrant` â†’ banco vetorial
  - `llm-service` â†’ endpoint de modelos open source
  - `postgres` â†’ suporte a dados tabulares (futuro uso em SQL Agent)

- **Ambiente de Desenvolvimento**
  - Python + Virtualenv (`.venv`)
  - ExecuÃ§Ã£o local com `streamlit run app/main.py`

---

## ğŸ”¹ LimitaÃ§Ãµes Atuais

- Agentes ainda funcionam de forma **isolada** (nÃ£o integrados entre si).
- Alguns parÃ¢metros configurÃ¡veis estÃ£o fixados em **valores default**.
- LangGraph implementado apenas com **router simples**.
- LLaMA Tiny em fase de **testes** para geraÃ§Ã£o contextual.

---

## ğŸ”¹ Futuras Melhorias

- IntegraÃ§Ã£o entre agentes para fluxos mais complexos.
- ParametrizaÃ§Ã£o dinÃ¢mica de configuraÃ§Ãµes via interface.
- ImplementaÃ§Ã£o de mÃ©tricas mais robustas (groundedness, relevance, PII detection).
- SubstituiÃ§Ã£o do router simples por workflows mais sofisticados no LangGraph.
